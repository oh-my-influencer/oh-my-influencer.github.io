"""
fetch_instagram.py

ì—­í• :
  1. Apify Instagram Hashtag Scraperë¡œ í•´ì‹œíƒœê·¸ë³„ ê²Œì‹œë¬¼ ìˆ˜ì§‘
  2. ê²Œì‹œë¬¼ì—ì„œ ownerUsername ì¶”ì¶œ (ì‹ ê·œë§Œ)
  3. Apify Instagram Profile Scraperë¡œ íŒ”ë¡œì›Œ ìˆ˜ ë“± ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
  4. í•„í„° ì ìš© í›„ ê¸°ì¡´ + ì‹ ê·œ ë³‘í•©í•´ì„œ instagram.json ì €ì¥

í™˜ê²½ë³€ìˆ˜:
  APIFY_API_TOKEN : Apify API í† í° (GitHub Secretìœ¼ë¡œ ì£¼ì…)

ì‹¤í–‰:
  APIFY_API_TOKEN=xxx uv run python scripts/fetch_instagram.py
"""

import json
import os
import sys
import time
from datetime import datetime, timezone
from pathlib import Path

import requests
from dotenv import load_dotenv

load_dotenv()

ROOT = Path(__file__).parent.parent
CONFIG_PATH = ROOT / "data" / "config.json"
OUTPUT_PATH = ROOT / "data" / "instagram.json"

APIFY_BASE = "https://api.apify.com/v2"
HASHTAG_ACTOR = "apify~instagram-hashtag-scraper"
PROFILE_ACTOR = "apify~instagram-profile-scraper"


# â”€â”€ Tier ë¶„ë¥˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_tier(followers: int) -> str:
    if followers >= 1_000_000:
        return "mega"
    if followers >= 100_000:
        return "macro"
    if followers >= 50_000:
        return "mid"
    if followers >= 10_000:
        return "micro"
    return "nano"


# â”€â”€ ê¸°ì¡´ ë°ì´í„° ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_existing(path: Path) -> dict[str, dict]:
    if not path.exists():
        return {}
    with open(path, encoding="utf-8") as f:
        data = json.load(f)
    return {acc["handle"]: acc for acc in data.get("influencers", [])}


# â”€â”€ Apify Actor ì‹¤í–‰ ê³µí†µ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_actor(
    token: str, actor_id: str, input_data: dict, timeout_sec: int = 300
) -> list[dict]:
    """Actor ì‹¤í–‰ â†’ ì™„ë£Œ ëŒ€ê¸° â†’ ê²°ê³¼ ë°˜í™˜"""
    run_resp = requests.post(
        f"{APIFY_BASE}/acts/{actor_id}/runs",
        params={"token": token},
        json=input_data,
        timeout=30,
    )
    run_resp.raise_for_status()
    run_data = run_resp.json()["data"]
    run_id = run_data["id"]
    dataset_id = run_data["defaultDatasetId"]
    print(f"   Actor ì‹¤í–‰ë¨ (run_id: {run_id})")

    # ì™„ë£Œ ëŒ€ê¸°
    for _ in range(timeout_sec // 5):
        time.sleep(5)
        status = requests.get(
            f"{APIFY_BASE}/actor-runs/{run_id}",
            params={"token": token},
            timeout=10,
        ).json()["data"]["status"]

        if status == "SUCCEEDED":
            break
        if status in ("FAILED", "ABORTED", "TIMED-OUT"):
            print(f"   âš ï¸ Actor ì‹¤íŒ¨: {status}", file=sys.stderr)
            return []
    else:
        print(f"   âš ï¸ íƒ€ì„ì•„ì›ƒ ({timeout_sec}ì´ˆ)", file=sys.stderr)
        return []

    items = requests.get(
        f"{APIFY_BASE}/datasets/{dataset_id}/items",
        params={"token": token, "format": "json"},
        timeout=30,
    )
    items.raise_for_status()
    return items.json()


# â”€â”€ Step 1: í•´ì‹œíƒœê·¸ â†’ username ëª©ë¡ ìˆ˜ì§‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def collect_usernames(token: str, hashtag: str, max_results: int) -> set[str]:
    posts = run_actor(
        token,
        HASHTAG_ACTOR,
        {
            "hashtags": [hashtag],
            "resultsLimit": max_results,
            "addParentData": False,
        },
    )
    return {post["ownerUsername"] for post in posts if post.get("ownerUsername")}


# â”€â”€ Step 2: username â†’ í”„ë¡œí•„ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_profiles(token: str, usernames: list[str]) -> list[dict]:
    """Profile Scraperë¡œ ê³„ì • ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¨ë‹¤. (50ê°œì”© ë°°ì¹˜)"""
    results = []
    chunk_size = 50
    for i in range(0, len(usernames), chunk_size):
        chunk = usernames[i : i + chunk_size]
        print(f"   í”„ë¡œí•„ ì¡°íšŒ ì¤‘: {len(chunk)}ê°œ")
        profiles = run_actor(
            token,
            PROFILE_ACTOR,
            {
                "usernames": chunk,
            },
            timeout_sec=300,
        )

        for p in profiles:
            handle = p.get("username") or p.get("handle", "")
            followers = p.get("followersCount") or p.get("followers", 0) or 0
            if not handle:
                continue
            results.append(
                {
                    "id": f"ig_{handle}",
                    "platform": "instagram",
                    "handle": handle,
                    "name": p.get("fullName") or handle,
                    "profile_url": f"https://www.instagram.com/{handle}/",
                    "profile_image": p.get("profilePicUrl")
                    or p.get("profilePicUrlHD")
                    or "",
                    "followers": followers,
                    "following": p.get("followsCount") or 0,
                    "posts_count": p.get("postsCount") or 0,
                    "engagement_rate": None,
                    "bio": (p.get("biography") or "")[:100],
                    "is_verified": p.get("verified") or False,
                    "category": ["skincare", "beauty"],
                    "tier": get_tier(followers),
                    "last_updated": datetime.now(timezone.utc).strftime("%Y-%m-%d"),
                }
            )
    return results


# â”€â”€ ë©”ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main() -> None:
    token = os.environ.get("APIFY_API_TOKEN", "")
    if not token:
        print("âŒ APIFY_API_TOKEN í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", file=sys.stderr)
        sys.exit(1)

    with open(CONFIG_PATH, encoding="utf-8") as f:
        config = json.load(f)

    ig_config = config.get("instagram", {})
    hashtags = ig_config.get("hashtags", [])
    max_results = ig_config.get("max_results_per_hashtag", 30)
    filters = config.get("filters", {})
    min_f = filters.get("min_followers", 10_000)
    max_f = filters.get("max_followers", 1_000_000)

    # ê¸°ì¡´ ê³„ì • ë¡œë“œ
    existing = load_existing(OUTPUT_PATH)
    print(f"ğŸ“‚ ê¸°ì¡´ ê³„ì • {len(existing)}ê°œ ë¡œë“œë¨\n")

    # Step 1: í•´ì‹œíƒœê·¸ë³„ username ìˆ˜ì§‘
    all_usernames: set[str] = set()
    for tag in hashtags:
        print(f"ğŸ” #{tag} í•´ì‹œíƒœê·¸ í¬ë¡¤ë§ ì¤‘...")
        usernames = collect_usernames(token, tag, max_results)
        new_in_tag = usernames - set(existing.keys()) - all_usernames
        all_usernames.update(new_in_tag)
        print(
            f"   â†’ ì‹ ê·œ {len(new_in_tag)}ê°œ / ì¤‘ë³µ {len(usernames) - len(new_in_tag)}ê°œ ìŠ¤í‚µ\n"
        )

    print(f"ğŸ“Š ì‹ ê·œ ë°œêµ´ username: {len(all_usernames)}ê°œ")

    # Step 2: ì‹ ê·œ usernameë§Œ í”„ë¡œí•„ ìƒì„¸ ì¡°íšŒ
    new_accounts: list[dict] = []
    if all_usernames:
        print("\nğŸ‘¤ í”„ë¡œí•„ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì¤‘ (Profile Scraper)...")
        new_accounts = fetch_profiles(token, list(all_usernames))
        print(f"   â†’ {len(new_accounts)}ê°œ í”„ë¡œí•„ ìˆ˜ì§‘ ì™„ë£Œ")

    # ê¸°ì¡´ + ì‹ ê·œ ë³‘í•© í›„ í•„í„° ì ìš©
    merged = {**existing, **{acc["handle"]: acc for acc in new_accounts}}
    filtered = [acc for acc in merged.values() if min_f <= acc["followers"] <= max_f]
    filtered.sort(key=lambda x: x["followers"], reverse=True)

    print(f"\nâœ… í•„í„° í†µê³¼: {len(filtered)}ê°œ (íŒ”ë¡œì›Œ {min_f:,} ~ {max_f:,})")

    OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)
    with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
        json.dump(
            {
                "generated_at": datetime.now(timezone.utc).isoformat(),
                "count": len(filtered),
                "influencers": filtered,
            },
            f,
            ensure_ascii=False,
            indent=2,
        )
    print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {OUTPUT_PATH}")


if __name__ == "__main__":
    main()
